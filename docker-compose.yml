services:
  blah-blah-answers:
    build: .
    ports:
      - "${PORT:-5000}:5000"
    env_file:
      - .env
    volumes:
      - ./data:/app/data
    restart: unless-stopped

  # Uncomment to run Ollama locally alongside the app.
  # NOTE: Set OLLAMA_URL=http://ollama:11434 in your .env (not localhost).
  # ollama:
  #   image: ollama/ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   restart: unless-stopped

# volumes:
#   ollama_data:
