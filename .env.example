# =============================================================================
# Blah Blah Answers - Configuration
# =============================================================================
# Copy this file to .env and fill in your values.

# --- AI Provider ---
# Which AI backend to use: "openai", "anthropic", or "ollama"
AI_PROVIDER=openai

# --- OpenAI ---
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini

# --- Anthropic ---
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# --- Gemini ---
GEMINI_API_KEY=
GEMINI_MODEL=gemini-2.5-flash

# --- Ollama (local) ---
# URL of your Ollama instance
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# --- Twilio ---
# Your Twilio Account SID and Auth Token (from https://console.twilio.com)
TWILIO_ACCOUNT_SID=
TWILIO_AUTH_TOKEN=

# --- System Prompt ---
# Default prompt for short answers (1 SMS segment = 160 chars)
SYSTEM_PROMPT=You are a helpful assistant answering questions via SMS. Keep responses extremely concise â€” under 160 characters total. No markdown formatting. Plain text only.

# Prompt used when user sends /context (up to 3 SMS segments = 480 chars)
CONTEXT_PROMPT=You are a helpful assistant answering questions via SMS. Provide a detailed response with citations or sources where relevant. Keep the response under 480 characters. No markdown formatting. Plain text only.

# --- Conversation Timeout ---
# Minutes of inactivity before conversation history auto-clears
CONTEXT_TIMEOUT_MINUTES=30

# --- Server ---
# Host and port for the Flask server
HOST=0.0.0.0
PORT=5000

# --- Conversation History ---
# Number of previous messages to include as context (0 to disable)
MAX_HISTORY=10
