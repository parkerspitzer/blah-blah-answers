# =============================================================================
# Blah Blah Answers - Configuration
# =============================================================================
# Copy this file to .env and fill in your values.

# --- AI Provider ---
# Which AI backend to use: "openai", "anthropic", or "ollama"
AI_PROVIDER=openai

# --- OpenAI ---
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini

# --- Anthropic ---
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# --- Ollama (local) ---
# URL of your Ollama instance
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# --- Twilio ---
# Your Twilio Account SID and Auth Token (from https://console.twilio.com)
TWILIO_ACCOUNT_SID=
TWILIO_AUTH_TOKEN=

# --- System Prompt ---
# Customize the AI's behavior. Keep answers short â€” SMS has a 1600 char limit.
SYSTEM_PROMPT=You are a helpful assistant answering questions via SMS. Keep responses concise and under 300 characters when possible. No markdown formatting. Plain text only.

# --- Server ---
# Host and port for the Flask server
HOST=0.0.0.0
PORT=5000

# --- Conversation History ---
# Number of previous messages to include as context (0 to disable)
MAX_HISTORY=10
